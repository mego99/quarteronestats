<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="stylesheet" type="text/css" href="styles/style.css">
  <!-- <link rel="stylesheet" type="text/css" href="styles/prism.css"> -->
  <script src="https://d3js.org/d3.v4.min.js"></script>
  <title>Quater One Project</title>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script src="scripts/d3.v4.0.0-rc.2.min.js"></script>
  <!-- <script src="scripts/prism.js"></script> -->
  <link rel="stylesheet" href="styles/color-brewer.css">
  <script src="styles/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>
<body>
  <h1>Quarter One Project</h1>
  <p>
    As a soon-to-be college freshman (hopefully!),
    I've been spending a fair share of my time scouring university websites, scanning colorful pamphlets, and making big decisions.
    When I stumbled upon the <a href="https://collegescorecard.ed.gov/data/documentation/">US College Scorecard</a>, I knew I had found my goldmine.
    This data, collected and compiled by the US Department of Education, is an extremely comprehensive and well-documented dataset freely available to
    the public. It contains information on colleges, their student body, cost of attendance, financial aid, and earnings after graduation.
  </p>
  <p>
    At first I tried to work through the raw downloaded data, but it became evident very quickly that this was too big of a dataset to handle.
    Luckily, an <a href="https://github.com/RTICWDT/open-data-maker/blob/master/API.md">API</a> is also provided,
    which can return only the results of specific queries. This API returns only a hundred data points per query.
    Below is a scatterplot I made, with the top 100 data points sorted by descending earnings after graduation, using <a href="https://github.com/d3/d3">D3</a>.
  </p>
  <svg id="first-scatter"></svg>
  <script src="charts.js"></script>
  <p>
    D3 is SVG-based, so performance is directly proportional to the number of elements (and in this case, data points) generated.
    This means that in order to harness the full potential of this dataset, I had to change my method.
    I decided to try working with Pandas, a data-handling library for Python.
  </p>
  <pre>
    <code class="language-python">
      import pandas as pd
      from pandas.io.json import json_normalize as jn
      import requests
      import json
      import math
      import matplotlib.pyplot as plt

      #get data through API in order to compute the number of iterations necessary
      url = "https://api.data.gov/ed/collegescorecard/v1/schools.json?api_key=3hZTlIbHmdMRcRWJ3NxdG8AvQPoW4Mdbilkm13At&school.operating=1&_sort=2013.earnings.10_yrs_after_entry.working_not_enrolled.mean_earnings:desc&_per_page=1&_page= %s &2013.earnings.10_yrs_after_entry.working_not_enrolled.mean_earnings__range=0..&2013.cost.attendance.academic_year__range=0..&fields=school.name"%(0)
      print("retrieving data count...")
      j = json.loads(requests.get(url).text)
      count = int(math.ceil(j["metadata"]["total"]/100))

      #loop through the same API request, incrementing page number each time
      sc = []
      for x in range(0,count):
          url = "https://api.data.gov/ed/collegescorecard/v1/schools.json?api_key=3hZTlIbHmdMRcRWJ3NxdG8AvQPoW4Mdbilkm13At&school.operating=1&_sort=2013.earnings.10_yrs_after_entry.working_not_enrolled.mean_earnings:desc&_per_page=100&_page= %s &2013.earnings.10_yrs_after_entry.working_not_enrolled.mean_earnings__range=0..&2013.cost.attendance.academic_year__range=0..&fields=school.name,2013.earnings.10_yrs_after_entry.working_not_enrolled.mean_earnings,2013.cost.attendance.academic_year,2013.admissions.admission_rate.overall,2013.admissions.sat_scores.average.overall,2013.aid.median_debt.number.overall,2013.student.retention_rate.four_year.full_time"%(x)
          print("retrieving data points %s to %s..."%(x*100,(x*100)+100))
          j = json.loads(requests.get(url).text)
          df = jn(j,"results")
          sc.append(df)

      #concatenate each retreived dataset into a single Pandas DataFrame and save to file
      sc = pd.concat(sc, axis=0)
      print("reassigning index...")
      sc.reset_index(inplace=True)
      sc.to_pickle("data.pkl")
      print("saved to file!")
    </code>
  </pre>
  <p>
    The above script retrieves all of the data from the API and saves it into an external file.
    Next, I took this data and made a picture with matplotlib.
  </p>
  <img class="plot" src="static/original.png"/>
  <p>
    <a href="http://www.statsmodels.org/dev/index.html">Statsmodels</a> has a handy <a href="http://www.statsmodels.org/dev/index.html">OLS</a>
    (ordinary least squares) regression calculator, so it told me the R-squared value, 84.9%.
    This value, coupled with the clearly exponential shape of the scatterplot, led me to believe that the data needed to be re-expressed
    to fit a linear regression.
  </p>
  <pre>
    <code>
            OLS Regression Results
      ==============================================================================
      Dep. Variable:                   cost   R-squared:                       0.849
      Model:                            OLS   Adj. R-squared:                  0.849
      Method:                 Least Squares   F-statistic:                 1.908e+04
      Date:                Sun, 22 Oct 2017   Prob (F-statistic):               0.00
      Time:                        12:00:41   Log-Likelihood:                -36217.
      No. Observations:                3384   AIC:                         7.244e+04
      Df Residuals:                    3383   BIC:                         7.244e+04
      Df Model:                           1
      Covariance Type:            nonrobust
      ==============================================================================
      coef    std err          t      P>|t|      [0.025      0.975]
      ------------------------------------------------------------------------------
      earnings       0.6017      0.004    138.131      0.000       0.593       0.610
      ==============================================================================
      Omnibus:                      120.566   Durbin-Watson:                   1.770
      Prob(Omnibus):                  0.000   Jarque-Bera (JB):              133.290
      Skew:                           0.486   Prob(JB):                     1.14e-29
      Kurtosis:                       2.967   Cond. No.                         1.00
      ==============================================================================
    </code>
  </pre>

</body>
</html>
